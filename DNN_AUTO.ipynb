{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer Dataset\n",
    "\n",
    "Leemos el dataset correspondiente: \n",
    "\n",
    "- data_windows: Es el dataset con vectores de 528 características\n",
    "- data_windows_264: Es el dataset con vectores de 264 características\n",
    "- data_windows_132: Es el dataset con vectores de 132 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "dataset = pd.read_csv('dataset/data_windows_132.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29848, 133)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso se preprocesamiento\n",
    "\n",
    "Se eliminan vectores que contentan datos Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete NAN values\n",
    "\"\"\"\n",
    "dataset_x = []\n",
    "dataset_y = []\n",
    "for label in range(1,17):\n",
    "    data = dataset[dataset.iloc[:,0] == label]\n",
    "    for index, row in data.iterrows():\n",
    "        if (len(dataset_x) <= (26*label)):\n",
    "            dataset_x.append(np.nan_to_num(dataset.iloc[index,1:].values))\n",
    "            dataset_y.append(dataset.iloc[index,0:1].values)\n",
    "        else:\n",
    "            break\n",
    "\"\"\"\n",
    "dataset_x = []\n",
    "dataset_y = []\n",
    "\n",
    "count = np.zeros(17)\n",
    "\n",
    "for label in range(1,17):\n",
    "    data = dataset[dataset.iloc[:,0] == label]\n",
    "    for index, row in data.iterrows():\n",
    "        if (len(dataset_x) <= (810*label)):#Balancear las clases\n",
    "            dataset_x.append(np.nan_to_num(dataset.iloc[index,1:].values))\n",
    "            dataset_y.append(dataset.iloc[index,0:1].values)\n",
    "            count[label]+=1\n",
    "    \n",
    "dataset_x = np.array(dataset_x)\n",
    "dataset_y = np.array(dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12961, 132), (12961, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x.shape,dataset_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[811. 810. 810. 810. 810. 810. 810. 810. 810. 810. 810. 810. 810. 810.\n",
      " 810. 810.]\n"
     ]
    }
   ],
   "source": [
    "print(count[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalice X values\n",
    "mean = np.sum(dataset_x,axis=0,keepdims=True)/dataset_x.shape[0]\n",
    "normal_variance = np.sum(dataset_x**2,axis=0,keepdims=True)/dataset_x.shape[0]\n",
    "dataset_x_normalice = dataset_x-mean\n",
    "dataset_x_normalice = dataset_x_normalice/np.sqrt(normal_variance+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_y_reshape = dataset_y.reshape(1,dataset_y.shape[0]).flatten().astype(int)\n",
    "dataset_y_reshape[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(12961,)\n"
     ]
    }
   ],
   "source": [
    "#Create Y binary class vector\n",
    "y_train_vector = dataset_y_reshape\n",
    "print(y_train_vector[0])\n",
    "print(y_train_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold\n",
    "Creamos los diferentes grupos de indices K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos en train y test\n",
    "#kf = KFold(n_splits=4)\n",
    "sss =  StratifiedShuffleSplit(n_splits=4,test_size=0.2, random_state=1)\n",
    "#kf.get_n_splits(dataset_x_normalice)\n",
    "sss.get_n_splits(dataset_x_normalice, y_train_vector)\n",
    "index_kfol = []\n",
    "for train_index, test_index in sss.split(dataset_x_normalice, y_train_vector):\n",
    "    index_kfol.append([train_index,test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo Test Configuration\n",
    "\n",
    "El método admite un vector de valores para cada hiperparámetro a probar y ejecuta la prueba con 4 KFolds para cada configuración posible, finalmente imprime los resultados en una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_configuration(lr_v = [0.001], beta_1_v=[0.9],beta_2_v=[0.999] ,epochs_n = [10], batch_size_n = [32], input_shape_n = 132):\n",
    "    \n",
    "    configuration = 1\n",
    "    table = [[\"Config\",\"Train 1\",\"Test 1\",\"Train 2\",\"Test 2\",\"Train 3\",\"Test 3\",\"Train 4\",\"Test 4\",\"Train Prom\",\"Test Prom\"]]\n",
    "    \n",
    "    #Dividimos en train y test\n",
    "    sss =  StratifiedShuffleSplit(n_splits=4,test_size=0.2,random_state=1)\n",
    "    sss.get_n_splits(dataset_x_normalice, y_train_vector)\n",
    "    index_kfol = []\n",
    "    for train_index, test_index in sss.split(dataset_x_normalice, y_train_vector):\n",
    "        index_kfol.append([train_index,test_index])\n",
    "                        \n",
    "    for batch in batch_size_n:\n",
    "        for epoch in epochs_n:\n",
    "            for beta2 in beta_2_v:\n",
    "                for beta1 in beta_1_v:\n",
    "                    for lr in lr_v:\n",
    "                        \n",
    "                        #For save accuracies\n",
    "                        results = {}\n",
    "                        \n",
    "                        # Create Model\n",
    "                        model = Sequential([\n",
    "                            \n",
    "                            Dense(128, activation='relu', input_shape=(input_shape_n,)),\n",
    "                            Dense(64, activation='relu'),\n",
    "                            Dense(32, activation='relu'),\n",
    "                            Dense(16, activation='softmax'),\n",
    "                        ])\n",
    "\n",
    "                        #Compile Model\n",
    "                        model.compile(\n",
    "                          optimizer=Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2, amsgrad=False),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'],\n",
    "                        )\n",
    "                        \n",
    "                        Wsave = model.get_weights()\n",
    "\n",
    "                        for g in range(4):\n",
    "\n",
    "                            model.set_weights(Wsave)\n",
    "\n",
    "                            #Get K-fold group \n",
    "                            train_index = index_kfol[g][0]\n",
    "                            test_index = index_kfol[g][1]\n",
    "\n",
    "                            x_train = dataset_x_normalice[train_index]\n",
    "                            y_train = y_train_vector[train_index]\n",
    "                            x_test = dataset_x_normalice[test_index]\n",
    "                            y_test = y_train_vector[test_index]  \n",
    "\n",
    "                            history = model.fit(\n",
    "                              x_train, # training data\n",
    "                              to_categorical(y_train-1), # training targets\n",
    "                              epochs=epoch,\n",
    "                              batch_size=batch,\n",
    "                              verbose=0 #Desactivar imprimir cada epoca.\n",
    "                            )\n",
    "\n",
    "                            results[str(g)+\"train\"] = history.history['accuracy'][-1]\n",
    "\n",
    "                            output = model.evaluate(x_test,to_categorical(y_test-1))\n",
    "\n",
    "                            results[str(g)+\"test\"] = output[1]\n",
    "                            \n",
    "                        #Print Results\n",
    "                        print(\"______________________Configuration-\"+str(configuration)+\"______________________\")\n",
    "                        print(\"LR:\"+str(lr)+\"- Beta_1:\"+str(beta1)+\"- Beta_2:\"+str(beta2))\n",
    "                        print(\"Epochs:\"+str(epoch)+\"- Bach:\"+str(batch))\n",
    "                        print(\"_________________________________________________________\")\n",
    "                        \n",
    "                        prom_train = []\n",
    "                        prom_test = []\n",
    "                        for g in range(4):\n",
    "                            prom_train.append(results[str(g)+\"train\"]*100)\n",
    "                            prom_test.append(results[str(g)+\"test\"]*100)\n",
    "                        \n",
    "                        table.append([configuration,\n",
    "                                      \"%.2f\" % round(results[\"0train\"]*100,2),\"%.2f\" % round(results[\"0test\"]*100,2),\n",
    "                                      \"%.2f\" % round(results[\"1train\"]*100,2),\"%.2f\" % round(results[\"1test\"]*100,2),\n",
    "                                      \"%.2f\" % round(results[\"2train\"]*100,2),\"%.2f\" % round(results[\"2test\"]*100,2),\n",
    "                                      \"%.2f\" % round(results[\"3train\"]*100,2),\"%.2f\" % round(results[\"3test\"]*100,2),\n",
    "                                      \"%.2f\" % round(sum(prom_train)/4,2),\"%.2f\" % round(sum(prom_test)/4,2)])\n",
    "                        print(\"_______________________ENDTEST_________________________\")   \n",
    "                        configuration = configuration+1\n",
    "                        \n",
    "    display(HTML(tabulate.tabulate(table, tablefmt='html')))                                      \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 1s 49us/step - loss: 0.7317 - accuracy: 0.7953\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.2817 - accuracy: 0.9178\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1970 - accuracy: 0.9401\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1627 - accuracy: 0.9495\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1341 - accuracy: 0.9566\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1116 - accuracy: 0.9653\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0987 - accuracy: 0.9675\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0913 - accuracy: 0.9688\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0758 - accuracy: 0.9738\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0748 - accuracy: 0.9748\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0627 - accuracy: 0.9787\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0553 - accuracy: 0.9805\n",
      "2593/2593 [==============================] - 0s 16us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.6978 - accuracy: 0.8024\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2730 - accuracy: 0.9193\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2031 - accuracy: 0.9350\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.1574 - accuracy: 0.9516\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1347 - accuracy: 0.9578\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1114 - accuracy: 0.9645\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0973 - accuracy: 0.9667\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0926 - accuracy: 0.9697\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0789 - accuracy: 0.9736\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0799 - accuracy: 0.9752\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0601 - accuracy: 0.9806\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0643 - accuracy: 0.9808\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.6974 - accuracy: 0.8056\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2650 - accuracy: 0.9237\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1924 - accuracy: 0.9413\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1478 - accuracy: 0.9545\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1200 - accuracy: 0.9617\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1008 - accuracy: 0.9652\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0988 - accuracy: 0.9683\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0763 - accuracy: 0.9738\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0786 - accuracy: 0.9736\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0641 - accuracy: 0.9775\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0616 - accuracy: 0.9797\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0572 - accuracy: 0.9816\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.6944 - accuracy: 0.8030\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2640 - accuracy: 0.9215\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1883 - accuracy: 0.9435\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.1458 - accuracy: 0.9552\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 45us/step - loss: 0.1193 - accuracy: 0.9633\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1073 - accuracy: 0.9639\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0913 - accuracy: 0.9708\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0936 - accuracy: 0.9703\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0768 - accuracy: 0.9761\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0650 - accuracy: 0.9794\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0636 - accuracy: 0.9787\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0616 - accuracy: 0.9795\n",
      "2593/2593 [==============================] - 0s 9us/step\n",
      "______________________Configuration-1______________________\n",
      "LR:0.001- Beta_1:0.9- Beta_2:0.999\n",
      "Epochs:12- Bach:16\n",
      "_________________________________________________________\n",
      "_______________________ENDTEST_________________________\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 1s 50us/step - loss: 0.7709 - accuracy: 0.7840\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.2717 - accuracy: 0.9207\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1842 - accuracy: 0.9456\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1483 - accuracy: 0.9559\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.1233 - accuracy: 0.9603\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1031 - accuracy: 0.9653\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0894 - accuracy: 0.9708\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0833 - accuracy: 0.9723\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0728 - accuracy: 0.9756\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0638 - accuracy: 0.9784\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0694 - accuracy: 0.9785\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0643 - accuracy: 0.9789\n",
      "2593/2593 [==============================] - 0s 16us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.7733 - accuracy: 0.7777\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2835 - accuracy: 0.9172\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1984 - accuracy: 0.9419\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1534 - accuracy: 0.9527\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1309 - accuracy: 0.9597\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1068 - accuracy: 0.9669\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0953 - accuracy: 0.9689\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0862 - accuracy: 0.9701\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0767 - accuracy: 0.9740\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0648 - accuracy: 0.9775\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0715 - accuracy: 0.9754\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0669 - accuracy: 0.9787\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.7780 - accuracy: 0.7837\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2708 - accuracy: 0.9222\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1913 - accuracy: 0.9406\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1516 - accuracy: 0.9530\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1252 - accuracy: 0.9625\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1063 - accuracy: 0.9661\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0944 - accuracy: 0.9683\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0909 - accuracy: 0.9709\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0756 - accuracy: 0.9740\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0735 - accuracy: 0.9751\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0641 - accuracy: 0.9783\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0566 - accuracy: 0.9802\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.7305 - accuracy: 0.7952\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2624 - accuracy: 0.9241\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1871 - accuracy: 0.9419\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1482 - accuracy: 0.9535\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1172 - accuracy: 0.9610\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1027 - accuracy: 0.9661\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0920 - accuracy: 0.9702\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0830 - accuracy: 0.9712\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0760 - accuracy: 0.9760\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0666 - accuracy: 0.9782\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0743 - accuracy: 0.9763\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0526 - accuracy: 0.9827\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "______________________Configuration-2______________________\n",
      "LR:0.00098- Beta_1:0.9- Beta_2:0.999\n",
      "Epochs:12- Bach:16\n",
      "_________________________________________________________\n",
      "_______________________ENDTEST_________________________\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 1s 51us/step - loss: 0.7567 - accuracy: 0.7835\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2707 - accuracy: 0.9150\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.2015 - accuracy: 0.9381\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1500 - accuracy: 0.9528\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1180 - accuracy: 0.9625\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1041 - accuracy: 0.9662\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.1031 - accuracy: 0.9674\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.0817 - accuracy: 0.9728\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0754 - accuracy: 0.9746\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0666 - accuracy: 0.9778\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0610 - accuracy: 0.9782\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0580 - accuracy: 0.9795\n",
      "2593/2593 [==============================] - 0s 16us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.7903 - accuracy: 0.7644\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.2803 - accuracy: 0.9169\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1963 - accuracy: 0.9391\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1465 - accuracy: 0.9556\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1194 - accuracy: 0.9616\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1099 - accuracy: 0.9670\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0991 - accuracy: 0.9675\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0871 - accuracy: 0.9709\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0802 - accuracy: 0.9744\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0702 - accuracy: 0.9769\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0652 - accuracy: 0.9786\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0619 - accuracy: 0.9796\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.7279 - accuracy: 0.7915\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.2589 - accuracy: 0.9241\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 42us/step - loss: 0.1781 - accuracy: 0.9444\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1493 - accuracy: 0.9521\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 46us/step - loss: 0.1193 - accuracy: 0.9620\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1104 - accuracy: 0.9637\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0895 - accuracy: 0.9695\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0807 - accuracy: 0.9731\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0814 - accuracy: 0.9712\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0706 - accuracy: 0.9747\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0594 - accuracy: 0.9799\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.0543 - accuracy: 0.9827\n",
      "2593/2593 [==============================] - 0s 13us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 47us/step - loss: 0.7347 - accuracy: 0.7878\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 46us/step - loss: 0.2526 - accuracy: 0.9267\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 46us/step - loss: 0.1795 - accuracy: 0.9455\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.1371 - accuracy: 0.9585\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 44us/step - loss: 0.1220 - accuracy: 0.9598\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 46us/step - loss: 0.1005 - accuracy: 0.9679\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0991 - accuracy: 0.9694\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0778 - accuracy: 0.9745\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0795 - accuracy: 0.9746\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0664 - accuracy: 0.9774\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0665 - accuracy: 0.9784\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 43us/step - loss: 0.0512 - accuracy: 0.9830\n",
      "2593/2593 [==============================] - 0s 11us/step\n",
      "______________________Configuration-3______________________\n",
      "LR:0.00096- Beta_1:0.9- Beta_2:0.999\n",
      "Epochs:12- Bach:16\n",
      "_________________________________________________________\n",
      "_______________________ENDTEST_________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 31us/step - loss: 0.8909 - accuracy: 0.7566\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 26us/step - loss: 0.3141 - accuracy: 0.9080\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.2166 - accuracy: 0.9344\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.1673 - accuracy: 0.9506\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.1356 - accuracy: 0.9570\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.1155 - accuracy: 0.9636\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0924 - accuracy: 0.9694\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0862 - accuracy: 0.9710\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0739 - accuracy: 0.9762\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 25us/step - loss: 0.0678 - accuracy: 0.9780\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0589 - accuracy: 0.9801\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0579 - accuracy: 0.9810\n",
      "2593/2593 [==============================] - 0s 16us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.8701 - accuracy: 0.7530\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.3140 - accuracy: 0.9101\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.2121 - accuracy: 0.9371\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.1675 - accuracy: 0.9481\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 25us/step - loss: 0.1400 - accuracy: 0.9547\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 25us/step - loss: 0.1188 - accuracy: 0.9626\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1033 - accuracy: 0.9673\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0895 - accuracy: 0.9742\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0798 - accuracy: 0.9739\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0700 - accuracy: 0.9768\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0623 - accuracy: 0.9791\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0564 - accuracy: 0.9823\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.8626 - accuracy: 0.7626\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2949 - accuracy: 0.9145\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2007 - accuracy: 0.9392\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1587 - accuracy: 0.9513\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1317 - accuracy: 0.9595\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1083 - accuracy: 0.9651\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0900 - accuracy: 0.9689\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0785 - accuracy: 0.9749\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0692 - accuracy: 0.9763\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0675 - accuracy: 0.9785\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0650 - accuracy: 0.9780\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0712 - accuracy: 0.9774\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.8465 - accuracy: 0.7573\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2825 - accuracy: 0.9161\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.1883 - accuracy: 0.9423\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.1466 - accuracy: 0.9538\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1283 - accuracy: 0.9607\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.1031 - accuracy: 0.9656\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.0886 - accuracy: 0.9709\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.0811 - accuracy: 0.9726\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.0704 - accuracy: 0.9764\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0645 - accuracy: 0.9785\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0578 - accuracy: 0.9801\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.0563 - accuracy: 0.9819\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "______________________Configuration-4______________________\n",
      "LR:0.001- Beta_1:0.9- Beta_2:0.999\n",
      "Epochs:12- Bach:32\n",
      "_________________________________________________________\n",
      "_______________________ENDTEST_________________________\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 30us/step - loss: 0.8895 - accuracy: 0.7479\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.3184 - accuracy: 0.9035\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2202 - accuracy: 0.9336\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1674 - accuracy: 0.9490\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1332 - accuracy: 0.9573\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1236 - accuracy: 0.9617\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1006 - accuracy: 0.9669\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0877 - accuracy: 0.9713\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0813 - accuracy: 0.9720\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0680 - accuracy: 0.9775\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0672 - accuracy: 0.9796\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0650 - accuracy: 0.9760\n",
      "2593/2593 [==============================] - 0s 15us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.8909 - accuracy: 0.7557\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.3131 - accuracy: 0.9061\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2117 - accuracy: 0.9365\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1689 - accuracy: 0.9511\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1395 - accuracy: 0.9585\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1192 - accuracy: 0.9640\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1047 - accuracy: 0.9688\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0866 - accuracy: 0.9717\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0835 - accuracy: 0.9759\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 25us/step - loss: 0.0658 - accuracy: 0.9769\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0637 - accuracy: 0.9785\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0615 - accuracy: 0.9796\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.8597 - accuracy: 0.7591\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.2927 - accuracy: 0.9119\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2029 - accuracy: 0.9385\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1579 - accuracy: 0.9519\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1273 - accuracy: 0.9592\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1071 - accuracy: 0.9664\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0916 - accuracy: 0.9704\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0852 - accuracy: 0.9717\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0811 - accuracy: 0.9747\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0765 - accuracy: 0.9755\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 27us/step - loss: 0.0621 - accuracy: 0.9791\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0621 - accuracy: 0.9815\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.8642 - accuracy: 0.7615\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.3026 - accuracy: 0.9101\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2026 - accuracy: 0.9377\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.1614 - accuracy: 0.9518\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1308 - accuracy: 0.9583\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1028 - accuracy: 0.9689\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0950 - accuracy: 0.9705\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0920 - accuracy: 0.9716\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0743 - accuracy: 0.9761\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.0679 - accuracy: 0.9774\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 36us/step - loss: 0.0619 - accuracy: 0.9805\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0614 - accuracy: 0.9813\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "______________________Configuration-5______________________\n",
      "LR:0.00098- Beta_1:0.9- Beta_2:0.999\n",
      "Epochs:12- Bach:32\n",
      "_________________________________________________________\n",
      "_______________________ENDTEST_________________________\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 30us/step - loss: 0.8560 - accuracy: 0.7565\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.3284 - accuracy: 0.9007\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2288 - accuracy: 0.9298\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1797 - accuracy: 0.9446\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1470 - accuracy: 0.9565\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1237 - accuracy: 0.9604\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 22us/step - loss: 0.1055 - accuracy: 0.9671\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0928 - accuracy: 0.9694\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0846 - accuracy: 0.9736\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0764 - accuracy: 0.9750\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0713 - accuracy: 0.9769\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0614 - accuracy: 0.9786\n",
      "2593/2593 [==============================] - 0s 16us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.8971 - accuracy: 0.7419\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.3079 - accuracy: 0.9110\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2240 - accuracy: 0.9347\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1652 - accuracy: 0.9512\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1399 - accuracy: 0.9566\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1226 - accuracy: 0.9616\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1048 - accuracy: 0.9671\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0928 - accuracy: 0.9686\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0796 - accuracy: 0.9742\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0708 - accuracy: 0.9780\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0591 - accuracy: 0.9811\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0587 - accuracy: 0.9816\n",
      "2593/2593 [==============================] - 0s 11us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.8299 - accuracy: 0.7666\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2901 - accuracy: 0.9125\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2103 - accuracy: 0.9383\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.1618 - accuracy: 0.9519\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1326 - accuracy: 0.9597\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1110 - accuracy: 0.9650\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0973 - accuracy: 0.9685\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0889 - accuracy: 0.9722\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0780 - accuracy: 0.9736\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0691 - accuracy: 0.9796\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0720 - accuracy: 0.9774\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0605 - accuracy: 0.9804\n",
      "2593/2593 [==============================] - 0s 9us/step\n",
      "Epoch 1/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.8571 - accuracy: 0.7529\n",
      "Epoch 2/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.2990 - accuracy: 0.9103\n",
      "Epoch 3/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.2085 - accuracy: 0.9370\n",
      "Epoch 4/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1582 - accuracy: 0.9503\n",
      "Epoch 5/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.1339 - accuracy: 0.9571\n",
      "Epoch 6/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.1135 - accuracy: 0.9647\n",
      "Epoch 7/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.1028 - accuracy: 0.9690\n",
      "Epoch 8/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0855 - accuracy: 0.9732\n",
      "Epoch 9/12\n",
      "10368/10368 [==============================] - 0s 23us/step - loss: 0.0708 - accuracy: 0.9760\n",
      "Epoch 10/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0621 - accuracy: 0.9805\n",
      "Epoch 11/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0624 - accuracy: 0.9793\n",
      "Epoch 12/12\n",
      "10368/10368 [==============================] - 0s 24us/step - loss: 0.0584 - accuracy: 0.9809\n",
      "2593/2593 [==============================] - 0s 10us/step\n",
      "______________________Configuration-6______________________\n",
      "LR:0.00096- Beta_1:0.9- Beta_2:0.999\n",
      "Epochs:12- Bach:32\n",
      "_________________________________________________________\n",
      "_______________________ENDTEST_________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Config</td><td>Train 1</td><td>Test 1</td><td>Train 2</td><td>Test 2</td><td>Train 3</td><td>Test 3</td><td>Train 4</td><td>Test 4</td><td>Train Prom</td><td>Test Prom</td></tr>\n",
       "<tr><td>1     </td><td>98.05  </td><td>94.95 </td><td>98.08  </td><td>95.06 </td><td>98.16  </td><td>96.07 </td><td>97.95  </td><td>94.79 </td><td>98.06     </td><td>95.22    </td></tr>\n",
       "<tr><td>2     </td><td>97.89  </td><td>94.87 </td><td>97.87  </td><td>95.80 </td><td>98.02  </td><td>95.03 </td><td>98.27  </td><td>94.87 </td><td>98.01     </td><td>95.14    </td></tr>\n",
       "<tr><td>3     </td><td>97.95  </td><td>94.72 </td><td>97.96  </td><td>95.80 </td><td>98.27  </td><td>94.95 </td><td>98.30  </td><td>95.03 </td><td>98.12     </td><td>95.12    </td></tr>\n",
       "<tr><td>4     </td><td>98.10  </td><td>94.87 </td><td>98.23  </td><td>95.10 </td><td>97.74  </td><td>96.14 </td><td>98.19  </td><td>95.41 </td><td>98.06     </td><td>95.38    </td></tr>\n",
       "<tr><td>5     </td><td>97.60  </td><td>95.03 </td><td>97.96  </td><td>95.91 </td><td>98.15  </td><td>95.03 </td><td>98.13  </td><td>95.14 </td><td>97.96     </td><td>95.28    </td></tr>\n",
       "<tr><td>6     </td><td>97.86  </td><td>95.10 </td><td>98.16  </td><td>94.37 </td><td>98.04  </td><td>95.22 </td><td>98.09  </td><td>95.18 </td><td>98.04     </td><td>94.97    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_t=[0.001,0.00098,0.00096]\n",
    "beta_1_t = [0.9]\n",
    "beta_2_t = [0.999]\n",
    "epochs_t = [12]\n",
    "batch_size_t = [16,32]\n",
    "test_configuration(lr_v=lr_t,beta_1_v=beta_1_t,beta_2_v=beta_2_t,epochs_n = epochs_t,batch_size_n = batch_size_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
